{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Structure\n",
    "\n",
    "## test vs training\n",
    "* is it even possible to predict a test set with this little data? We have notes and chords as guidance for what the test set should be predicted on. If we don't see those notes or chords elsewhere, do we have any chance of succeeding?\n",
    "* or should we just say fuck it, and try, and if we can make it reasonably far we'll add a few more training inputs (from either Mingus or some other band playing the real book. That way we know how the test set sound could sound)\n",
    "\n",
    "## inputs\n",
    "* amplitude vs time or frequency (what kind of FFT?) vs time\n",
    "* real book vs time\n",
    "    * notes on treble, chords on bass?\n",
    "    * how closely do we have to map it to the song (I think pretty fucking closely)\n",
    "    * how much data per note/chord (there are modifiers, pauses, etc.)\n",
    "    * the Magenta Note Sequence actually looks pretty good for this -- why not use their helper functions to create sequences of notes and chords for input? \n",
    "* is the real book the only input + memory? And we're learning the memory?\n",
    "\n",
    "## model RNN\n",
    "* notice delta compared to the real book -- is that delta consistent?\n",
    "* Does it make sense to build a GAN that goes from note input to sound output, and one that goes from sound output to not input and try to make the discriminator identify if it's real or not? Yes!\n",
    "* Is there an advantage to using a CNN of the spectograph? All d\n",
    "* forgetting or not\n",
    "* bidrectional?\n",
    "* what is the memory? That feels like how the band modifies the notes -- (how we translate the real book to the wave form -- modifications and global sound). \n",
    "* RNN structure:\n",
    "    * output of previous step is the amplitude played, then should be input into the next step, along with real book.\n",
    "    * all a's from previous step should be passed along\n",
    "    * DanQ structure (cnn -> rnn across a reduced space -> fully connected). Rnns keep parameters small, but blow up gradient calculations. \n",
    "\n",
    "### Measures. Format is: note, how long\n",
    "\n",
    "* #### Pre\n",
    "    * C (low) 1/8\n",
    "* #### 1\n",
    "    * notes\n",
    "    * F 1/8, A 1/8, A 1/12, F 1/12, A 1/12, B 1/8, A 1/4, F 1/16, D 1/16\n",
    "    * chords\n",
    "    * F7#9 (F - A - C - Eb - G#)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "   \n",
    "* #### 2\n",
    "    * notes\n",
    "    * F 1/8, A 1/4, F 1/16, E 1/16, F 3/8, C 1/8\n",
    "    * chords\n",
    "    * GbMaj7 (Gb - Bb - Db - F)\n",
    "    * B#11 7 (B - A - D# - E#)???\n",
    "* #### 3\n",
    "    * notes\n",
    "    * F 1/8, A 1/8, A 1/12, F 1/12, A 1/12, Cb 1/8, B 1/4, F 1/16, E 1/16\n",
    "    * chords\n",
    "    * Eb7sus4 (Eb - Ab - Bb - Db) \n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 4\n",
    "    * notes\n",
    "    * F 1/8, A 1/4, F 1/16, E 1/16, F 3/8, F 1/8\n",
    "    * chords\n",
    "    * Eb7sus4 (Eb - Ab - Bb - Db)\n",
    "    * F7 (F - A - C - Eb)\n",
    "* #### 5\n",
    "    * notes\n",
    "    * C 1/8, E (octave up) 1/8, E (octave up) 1/12, F 1/12, A 1/12, B 1/8, A 1/4, F 1/16, A 1/16\n",
    "    * chords\n",
    "    * Bbm7 (Bb - Db - F - Ab)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 6\n",
    "    * notes\n",
    "    * C 1/8, F (octave up) 1/8, F (octave up) 1/12, F 1/12, B 1/12, E (octave up) 2/12, C 1/12,  A 1/12, E# 1/12, D (low) 1/12\n",
    "    * chords\n",
    "    * Gm7 G - Bb - D - F\n",
    "    * C7#5 C - E - G# - Bb\n",
    "* #### 7 ?\n",
    "    * notes\n",
    "    * A 1/6, C flat 1/6, F 1/6, E sharp 1/6, C 1/6, G 1/6\n",
    "    * chords\n",
    "    * D7 D - F# - A - C\n",
    "    * G7  G - B - D - F\n",
    "* #### 8\n",
    "    * notes\n",
    "    * A 1/2, F 3/8, Cb 1/16, B 1/16\n",
    "    * chords\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "    * GbMaj7 (Gb - Bb - Db - F)\n",
    "* #### 9\n",
    "    * notes\n",
    "    *  A 1/2, F 1/2\n",
    "    * chords\n",
    "    * B^7_6 ?\n",
    "    * Bb7 Bb - D - F - Ab\n",
    "* #### 10\n",
    "    * notes\n",
    "    * B 1/8, A 1/8, F 1/8, E 1/8, Cb 1/8, B 1/8, A 1/8, F 1/8\n",
    "    * chords\n",
    "    * C7 C - E - G - Bb\n",
    "    * Eb7 Eb - G - Bb - Db\n",
    "* #### 11\n",
    "    * notes\n",
    "    * A 1/2, F 1/2\n",
    "    * chords\n",
    "    * F7#9 (F - A - C - Eb - G#)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 12\n",
    "    * notes\n",
    "    * C 1/6, B 1/6, A 1/6, F 1/6, E 1/6, C (low) 1/6\n",
    "    * chords\n",
    "    * GbMaj#11 G Bb C D Gb (Gb Bb B Db F?)\n",
    "    * B7b5 B Eb F A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import array_statistics, read_wav, append_array\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "GPPH_DATA_DIRECTORY = '/Users/pbatra/projects/lil_wayne/data/10_17_2018'\n",
    "\n",
    "gpph_files = [f for f in os.listdir(GPPH_DATA_DIRECTORY) if os.path.isfile(os.path.join(GPPH_DATA_DIRECTORY, f))]\n",
    "print gpph_files\n",
    "\n",
    "for file_ in gpph_files[:1]:\n",
    "    filename = os.path.join(GPPH_DATA_DIRECTORY, file_)\n",
    "    x, sr = read_wav(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_array_dumbly(x, window):\n",
    "    total_steps = len(x)\n",
    "    y = np.zeros((total_steps,))\n",
    "    for idx in range(total_steps/window):\n",
    "        y[(idx * window):((idx+1) * window)] = np.mean(x[(idx*window): ((idx+1) * window)])\n",
    "    return y\n",
    "\n",
    "def sample_array_tft(x, window):\n",
    "    array_statistics(x, 44100)\n",
    "    tft_x = librosa.stft(x)\n",
    "    mean_values = np.mean(abs(tft_x), axis = 0)\n",
    "    print np.count_nonzero(tft_x[abs(tft_x) > 0])\n",
    "    tft_x[(abs(tft_x) - window * mean_values) < 0] = 0\n",
    "    print np.count_nonzero(tft_x[abs(tft_x) > 0])\n",
    "    itft_tft_x = librosa.istft(tft_x)\n",
    "    array_statistics(itft_tft_x, 44100)\n",
    "    return itft_tft_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x.shape, sr\n",
    "#print filepath\n",
    "#ipd.Audio(filepath)\n",
    "ipd.Audio(sample_array_tft(x,1.0), rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_x = librosa.stft(x, 2048)\n",
    "tft_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_slice = np.mean(abs(tft_x), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = np.random.rand(3,10)\n",
    "mean_per_slice = np.mean(abs(blah), axis=0)\n",
    "print blah\n",
    "print mean_per_slice\n",
    "blah[(blah-mean_per_slice) < 0] = 0\n",
    "print blah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
