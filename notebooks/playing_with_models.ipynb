{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Structure\n",
    "\n",
    "## test vs training\n",
    "* is it even possible to predict a test set with this little data? We have notes and chords as guidance for what the test set should be predicted on. If we don't see those notes or chords elsewhere, do we have any chance of succeeding?\n",
    "* or should we just say fuck it, and try, and if we can make it reasonably far we'll add a few more training inputs (from either Mingus or some other band playing the real book. That way we know how the test set sound could sound)\n",
    "\n",
    "## inputs/outputs\n",
    "* amplitude vs time or frequency (what kind of FFT?) vs time\n",
    "* real book vs time\n",
    "    * notes on treble, chords on bass?\n",
    "    * how closely do we have to map it to the song (I think pretty fucking closely)\n",
    "    * how much data per note/chord (there are modifiers, pauses, etc.)\n",
    "    * the Magenta Note Sequence actually looks pretty good for this -- why not use their helper functions to create sequences of notes and chords for input? \n",
    "* are we predicting the TFTF or the waveform directly\n",
    "\n",
    "## model RNN\n",
    "* we are trying to describe a band's interpretation of the real book.\n",
    "* Does it make sense to build a GAN that goes from note input to sound output, and one that goes from sound output to which band? Absofuckinglutely.\n",
    "* What are we trying to predict -- the spectograph or the waveform?\n",
    "* simple RNN structures to try:\n",
    "    * bidirectional\n",
    "    * GRU vs LSTM\n",
    "    * model that encodes all of the notes first, then produces the output all at once.\n",
    "    * model that produces part of the wave form one time-step at a time (As it's reading in). How does the bi-directional fit into this?\n",
    "        * would the model need output from last set as input?\n",
    "\n",
    "### Measures. Format is: note, how long\n",
    "\n",
    "* #### Pre\n",
    "    * C (low) 1/8\n",
    "* #### 1\n",
    "    * notes\n",
    "    * F 1/8, A 1/8, A 1/12, F 1/12, A 1/12, B 1/8, A 1/4, F 1/16, D 1/16\n",
    "    * chords\n",
    "    * F7#9 (F - A - C - Eb - G#)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "   \n",
    "* #### 2\n",
    "    * notes\n",
    "    * F 1/8, A 1/4, F 1/16, E 1/16, F 3/8, C 1/8\n",
    "    * chords\n",
    "    * GbMaj7 (Gb - Bb - Db - F)\n",
    "    * B#11 7 (B - A - D# - E#)???\n",
    "* #### 3\n",
    "    * notes\n",
    "    * F 1/8, A 1/8, A 1/12, F 1/12, A 1/12, Cb 1/8, B 1/4, F 1/16, E 1/16\n",
    "    * chords\n",
    "    * Eb7sus4 (Eb - Ab - Bb - Db) \n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 4\n",
    "    * notes\n",
    "    * F 1/8, A 1/4, F 1/16, E 1/16, F 3/8, F 1/8\n",
    "    * chords\n",
    "    * Eb7sus4 (Eb - Ab - Bb - Db)\n",
    "    * F7 (F - A - C - Eb)\n",
    "* #### 5\n",
    "    * notes\n",
    "    * C 1/8, E (octave up) 1/8, E (octave up) 1/12, F 1/12, A 1/12, B 1/8, A 1/4, F 1/16, A 1/16\n",
    "    * chords\n",
    "    * Bbm7 (Bb - Db - F - Ab)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 6\n",
    "    * notes\n",
    "    * C 1/8, F (octave up) 1/8, F (octave up) 1/12, F 1/12, B 1/12, E (octave up) 2/12, C 1/12,  A 1/12, E# 1/12, D (low) 1/12\n",
    "    * chords\n",
    "    * Gm7 G - Bb - D - F\n",
    "    * C7#5 C - E - G# - Bb\n",
    "* #### 7 ?\n",
    "    * notes\n",
    "    * A 1/6, C flat 1/6, F 1/6, E sharp 1/6, C 1/6, G 1/6\n",
    "    * chords\n",
    "    * D7 D - F# - A - C\n",
    "    * G7  G - B - D - F\n",
    "* #### 8\n",
    "    * notes\n",
    "    * A 1/2, F 3/8, Cb 1/16, B 1/16\n",
    "    * chords\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "    * GbMaj7 (Gb - Bb - Db - F)\n",
    "* #### 9\n",
    "    * notes\n",
    "    *  A 1/2, F 1/2\n",
    "    * chords\n",
    "    * B^7_6 ?\n",
    "    * Bb7 Bb - D - F - Ab\n",
    "* #### 10\n",
    "    * notes\n",
    "    * B 1/8, A 1/8, F 1/8, E 1/8, Cb 1/8, B 1/8, A 1/8, F 1/8\n",
    "    * chords\n",
    "    * C7 C - E - G - Bb\n",
    "    * Eb7 Eb - G - Bb - Db\n",
    "* #### 11\n",
    "    * notes\n",
    "    * A 1/2, F 1/2\n",
    "    * chords\n",
    "    * F7#9 (F - A - C - Eb - G#)\n",
    "    * Db7 (Db - F - Ab - B)\n",
    "* #### 12\n",
    "    * notes\n",
    "    * C 1/6, B 1/6, A 1/6, F 1/6, E 1/6, C (low) 1/6\n",
    "    * chords\n",
    "    * GbMaj#11 G Bb C D Gb (Gb Bb B Db F?)\n",
    "    * B7b5 B Eb F A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from utilities import array_statistics, read_wav, append_array\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "input_data = [] # [(filename), rb_seq, sr), ...]\n",
    "measure_1 = np.zeros((1, ))\n",
    "#x, sr = append_array(x, 22050, total_duration=5, octave=3, note_array=[('C', 1/8.0)])\n",
    "measure_1, sr = append_array(measure_1, 44100, total_duration=4, octave=4, note_array=[('F', 1/8.0), ('A', 1/8.0), ('A', 1/12.0), ('F', 1/12.0), ('A', 1/12.0), \n",
    "                                ('B', 1/8.0), ('A', 1/4.0), ('F', 1/16.0), ('D', 1/16.0)]) \n",
    "\n",
    "input_data.append(('pork-pie1.wav', measure_1, sr))\n",
    "\n",
    "\n",
    "GPPH_DATA_DIRECTORY = '/Users/pbatra/projects/lil_wayne/data/10_17_2018'\n",
    "\n",
    "gpph_files = [f for f in os.listdir(GPPH_DATA_DIRECTORY) if os.path.isfile(os.path.join(GPPH_DATA_DIRECTORY, f))]\n",
    "print gpph_files\n",
    "output_data = [] #[(filename, seq, sr), ...]\n",
    "\n",
    "for file_ in gpph_files:\n",
    "    filename = os.path.join(GPPH_DATA_DIRECTORY, file_)\n",
    "    x, sr = read_wav(filename)\n",
    "    output_data.append((file_, x, sr))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_array_dumbly(x, window):\n",
    "    total_steps = len(x)\n",
    "    y = np.zeros((total_steps,))\n",
    "    for idx in range(total_steps/window):\n",
    "        y[(idx * window):((idx+1) * window)] = np.mean(x[(idx*window): ((idx+1) * window)])\n",
    "    return y\n",
    "\n",
    "def sample_array_tft(x, window):\n",
    "    array_statistics(x, 44100)\n",
    "    tft_x = librosa.stft(x)\n",
    "    print tft_x.shape\n",
    "    mean_values = np.mean(abs(tft_x), axis = 0)\n",
    "    print \"original non-zero amplitudes: %s\" % np.count_nonzero(tft_x[abs(tft_x) > 0])\n",
    "    tft_x[(abs(tft_x) - window * mean_values) < 0] = 0\n",
    "    print \"reduced non-zero amplitudes: %s\" % np.count_nonzero(tft_x[abs(tft_x) > 0])\n",
    "    itft_tft_x = librosa.istft(tft_x)\n",
    "    array_statistics(itft_tft_x, 44100)\n",
    "    return tft_x, itft_tft_x\n",
    "\n",
    "#print filepath\n",
    "#ipd.Audio(filepath)\n",
    "#tft_x, itft_tft_x = sample_array_tft(output_data[0][1], 0.5)\n",
    "#ipd.Audio(itft_tft_x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_data[0][1], rate=output_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(input_data[0][1], rate=input_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(hyperparameters):\n",
    "    \"\"\"\n",
    "    create placeholders for input data\n",
    "    \"\"\"\n",
    "    x = tf.placeholder(tf.float32, shape=[hyperparameters['batch_size'], \n",
    "                                          hyperparameters['time_steps'], \n",
    "                                          hyperparameters['input_features']], \n",
    "                                          name = 'x') \n",
    "    y_true = tf.placeholder(tf.float32, shape=[hyperparameters['batch_size'], \n",
    "                                          hyperparameters['time_steps'], \n",
    "                                          hyperparameters['input_features']], \n",
    "                                          name = 'y_true') # output wav (-1, 1)\n",
    "    return x, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, hyperparameters):\n",
    "    \"\"\"\n",
    "    returns -1 to 1 output\n",
    "    \"\"\"\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(hyperparameters['num_units'],\n",
    "                                   use_peepholes=False,\n",
    "                                   cell_clip=None,\n",
    "                                   initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                   num_proj=1,\n",
    "                                   proj_clip=1.0,\n",
    "                                   num_unit_shards=None,\n",
    "                                   num_proj_shards=None,\n",
    "                                   forget_bias=1.0,\n",
    "                                   state_is_tuple=True,\n",
    "                                   activation=tf.nn.tanh,\n",
    "                                   reuse=None,\n",
    "                                   name=None,\n",
    "                                   dtype=tf.float32\n",
    "                                  )\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=cell,\n",
    "                                      inputs=x,\n",
    "                                      sequence_length=None,\n",
    "                                      initial_state=None,\n",
    "                                      dtype=tf.float32,\n",
    "                                      parallel_iterations=None,\n",
    "                                      swap_memory=False,\n",
    "                                      time_major=False,\n",
    "                                      scope=None\n",
    "                                  )\n",
    "                                   \n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(outputs, y_true):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \"\"\"\n",
    "    cost = tf.losses.mean_squared_error(labels=y_true, predictions=outputs)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(training_seq, true_seq):\n",
    "    hyperparameters = {}\n",
    "    hyperparameters['input_features'] = training_seq.shape[2] #(pure input wav for now, moving to something else later that will include chords, maybe hz?)\n",
    "    hyperparameters['batch_size'] = training_seq.shape[0]\n",
    "    hyperparameters['time_steps'] = training_seq.shape[1]\n",
    "    hyperparameters['num_units'] = 100\n",
    "    hyperparameters['learning_rate'] = 0.009\n",
    "    hyperparameters['training_epochs'] = 100\n",
    "    hyperparameters['display_step'] = hyperparameters['training_epochs']/10\n",
    "    output_results = {}\n",
    "    model_start_time = datetime.now()\n",
    "\n",
    "    costs  = []\n",
    "    predictions = []\n",
    "\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    x, y_true = create_placeholders(hyperparameters)\n",
    "    outputs, state = forward_propagation(x, hyperparameters)\n",
    "    cost = compute_cost(outputs, y_true)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = hyperparameters['learning_rate']).minimize(cost)\n",
    "    #variable_saver = tf.train.Saver() #in case we just want to reload variables at some point\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        #writer = tf.summary.FileWriter(folder + '_logs', sess.graph)\n",
    "        #writer.close()\n",
    "        # Train\n",
    "        for epoch in range(hyperparameters['training_epochs']):\n",
    "            epoch_start_time = datetime.now()\n",
    "            #randomly shuffle training_indices\n",
    "            #np.random.shuffle(randomized_training_indices)\n",
    "            #for mb_index in range(0, training_size, hyperparameters['minibatch_size']):\n",
    "            #    mb_indices = randomized_training_indices[mb_index:mb_index + hyperparameters['minibatch_size']]\n",
    "            #    mb_training_input = training_input[mb_indices]\n",
    "            #    mb_training_output=  training_output[mb_indices]\n",
    "            _, cost_step, prediction_step =sess.run(\n",
    "                                                    (optimizer, cost, outputs),\n",
    "                                                    feed_dict=\n",
    "                                                    {x: training_seq, y_true: true_seq})\n",
    "            costs.append(cost_step)\n",
    "            predictions.append(prediction_step)\n",
    "            if epoch % hyperparameters['display_step'] == 0:    \n",
    "                print \"epoch: %s, %s, %s\" % (epoch, cost_step, datetime.now() - epoch_start_time)\n",
    "\n",
    "        print \"epoch: %s, %s, %s\" % (epoch, cost_step, datetime.now() - epoch_start_time)\n",
    "        #DONE\n",
    "        print \"\\ttotal_time: %s\" % (datetime.now() - model_start_time)\n",
    "        return costs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 1\n",
    "time_steps = 50000\n",
    "training_batches = np.zeros([batches, time_steps,1])\n",
    "output_batches = np.zeros([batches, time_steps, 1])\n",
    "for b in range(batches):\n",
    "    training_batches[b,:,0] = input_data[b][1][:time_steps]\n",
    "    output_batches[b,:,0] = output_data[b][1][:time_steps]\n",
    "costs, predictions = run_model(training_batches, output_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_statistics(training_batches[0,1000:2000,0], sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(predictions)\n",
    "epoch = 0\n",
    "predictions[epoch].shape\n",
    "playable = np.squeeze(predictions[epoch][0,:,0])\n",
    "delta = np.squeeze(predictions[epoch][0,:,0] - output_batches[0,:,0])\n",
    "array_statistics(playable[1000:2000], 44100)\n",
    "array_statistics(delta, 44100)\n",
    "ipd.Audio(playable, rate = 44100)\n",
    "#ipd.Audio(delta, rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playable = np.squeeze(output_batches[0,:,0])\n",
    "array_statistics(playable, 44100)\n",
    "ipd.Audio(playable, rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
